MLDATASET_PartiallyCleaned <- read.csv("C:/Users/fe/Downloads/MLDATASET_PartiallyCleaned.csv", header = T)
str(MLDATASET_PartiallyCleaned) 
summary(MLDATASET_PartiallyCleaned)
#MLDATASET_PartiallyCleaned$How.Many.Times.File.Seen[MLDATASET_PartiallyCleaned$How.Many.Times.File.Seen>=5] <- 5
summary(MLDATASET_PartiallyCleaned$How.Many.Times.File.Seen)
hist(MLDATASET_PartiallyCleaned$How.Many.Times.File.Seen)

curAlpha
??glmnet
cv.glmnet()


# Set up grid and cross validation method for train function
lambda_grid <- seq(0, 3, 0.1)
alpha_grid <- seq(0, 1, 0.1)

trnCtrl <- trainControl(method = "repeatedCV",
                        number = 10,
                        )
??trainControl
srchGrid <- expand.grid(.alpha = alpha_grid, .lambda = lambda_grid)

# Cross validation
my_train <- train(y ~., data,
                  method = "glmnet",
                  tuneGrid = srchGrid,
                  trControl = trnCtrl)


###in

alphasOfInterest <- seq(0, 1, 0.1)

# Step 1: Do all crossvalidations for each alpha
cvs <- lapply(alphasOfInterest, function(0.3) {
  cv.glmnet(x, y, alpha = 0.3, family = "binomial")
})
??curi
# Step 2: Collect the optimum lambda for each alpha
optimumPerAlpha <- sapply(seq_along(alphasOfInterest), function(curi) {
  curcvs <- cvs[[curi]]
  curAlpha <- alphasOfInterest[curi]
  indOfMin <- match(curcvs$lambda.min, curcvs$lambda)
  c(lam = curcvs$lambda.min, alph = curAlpha, cvup = curcvs$cvup[indOfMin])
})

# Step 3: Find the overall optimum
posOfOptimum <- which.min(optimumPerAlpha["lam", ])
overall.lambda.min <- optimumPerAlpha["lam", posOfOptimum]
overall.alpha.min <- optimumPerAlpha["alph", posOfOptimum]
overall.criterionthreshold <- optimumPerAlpha["cvup", posOfOptimum]

# Step 4: Now check for each alpha which lambda is the best within the threshold
corrected1se <- sapply(seq_along(alphasOfInterest), function(curi) {
  curcvs <- cvs[[curi]]
  lams <- curcvs$lambda
  lams[lams < overall.lambda.min] <- NA
  lams[curcvs$cvm > overall.criterionthreshold] <- NA
  lam1se<-max(lams, na.rm = TRUE)
  c(lam = lam1se, alph = alphasOfInterest[curi])
})

# Step 5: Find the best (lowest) of these lambdas
overall.lambda.1se <- max(corrected1se["lam", ])
pos <- match(overall.lambda.1se, corrected1se["lam", ])
overall.alpha.1se <- corrected1se["alph", pos]

# Best parameters
alpha_without_caret[r] <- as.numeric(overall.alpha.1se) # alpha according to glmnet only
lambda_without_caret[r] <- as.numeric(overall.lambda.1se) # lambda according to glmnet only

# Elastic net with best parameters
mod_elnet_wc <- glmnet(x = as.matrix(data[colnames(data) %in% "y" == FALSE]), 
                       y = data$y, alpha = alpha_without_caret[r], family = "gaussian", lambda = lambda_without_caret[r])



####2 again
alpha_caret <- numeric()
lambda_caret <- numeric()
MSE_caret <- numeric()
alpha_without_caret <- numeric()
lambda_without_caret <- numeric()
MSE_without_caret <- numeric()

R <- 20 # Simulation runs

for(r in 1:R) {
  
  
  ##### Tune parameteres with caret and glmnet #####
  
  
  # Set up grid and cross validation method for train function
  lambda_grid <- seq(0, 3, 0.1)
  alpha_grid <- seq(0, 1, 0.1)
  
  trnCtrl <- trainControl(method = "repeatedCV",
                          number = 10,
                          )
  
  srchGrid <- expand.grid(.alpha = alpha_grid, .lambda = lambda_grid)
  
  # Cross validation
  my_train <- train(y ~., train.data,
                    method = "glmnet",
                    tuneGrid = srchGrid,
                    trControl = trnCtrl)
  
  View(x)
  # Best parameters
  alpha_caret[r] <- as.numeric(my_train$bestTune[1]) # alpha according to caret
  lambda_caret[r] <- as.numeric(my_train$bestTune[2]) # lambda according to caret
  
  # Elastic net with best parameters
  mod_elnet <- cv.glmnet(x, y, alpha = alpha_caret[r], family = "binomial", lambda = lambda_caret[r])
    
}
