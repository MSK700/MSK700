#Importing necessary libraries to be used (if you dont have these libraries installed first install them by using; install.packages("libraryname"))

library(tidyverse)
library(corrplot)
library(data.table)
library(readr)
library(dplyr)
library(caret)
library(glmnet)
library(party)
library(ipred)
library(randomForest)

#Viewing the data
##We name the initial partially cleaned data set as MLini
MLini <- read.csv("C:/Users/fe/Downloads/MLDATASET_PartiallyCleaned.csv", header = T)
View(MLini)
str(MLini) 
summary(MLini)
summary(MLini$How.Many.Times.File.Seen)
summary(MLini$Threads.Started)

#using hist function to draw histogram to check the data
hist(MLini$How.Many.Times.File.Seen)
hist(MLini$Threads.Started)

MLini %>% select_if(is.numeric) %>% cor() %>% corrplot()
#cleaning data as per instructions

MLini$How.Many.Times.File.Seen[MLini$How.Many.Times.File.Seen>=65535] <- NA
#we figured that the value we replaced with NA was an outlier and have decided to remove it, an alternate method could have been to replace it by the median value

# using summary and histogram function to check if we have successfully removed the outlier with NA

summary(MLini$How.Many.Times.File.Seen)
hist(MLini$How.Many.Times.File.Seen)

# now doing the same i.e. removing the outlier from the threads started column and then converting it to a categorical variable. we say that any value above 5 is equal to 5 threads started

MLini$Threads.Started[MLini$Threads.Started>=5] <-5

hist(MLini$Threads.Started)

#converting the numeric variable to categorical variable

MLini$Threads.Started = as.factor(MLini$Threads.Started)

#normalizing the characters in URL by using the log function
hist(MLini$Characters.in.URL)
summary(MLini$Characters.in.URL)
MLini$Characters.in.URL = log(MLini$Characters.in.URL)

#removing all the NA and blank values by na.omit() function

ML.cleaned = na.omit(MLini)
str(ML.cleaned)
116249

ML.cleaned %>% select_if(is.numeric) %>% cor() %>% corrplot()
ggplot(ML.cleaned, aes(x = Download.Speed, y = File.Size.Bytes, fill = Threads.Started)) + geom_boxplot()
ggplot(ML.cleaned, aes(x =Actually.Malicious , y = File.Size.Bytes, fill = Initial.Statistical.Analysis)) + geom_boxplot()
ggplot(ML.cleaned, aes(x = `Actually.Malicious`, y = `File.Size.Bytes`, fill=`Initial.Statistical.Analysis`)) + 
  geom_bar(stat="identity") + theme_minimal()

#now that we have cleaned the data we will create test and train data before going on training the models; the instructions are against practice because it says to take 30% in train, usually we take 70% in train and 30% in test

set.seed(10288996)

train_ind = rbinom(nrow(ML.cleaned), 1, 0.3)

train.data = subset(ML.cleaned, train_ind == 1)[,-c(1,16)]

test.data = subset(ML.cleaned, train_ind == 0)[,-c(1,16)]

str(train.data)

str(test.data)

nrow(train.data)

nrow(test.data)

# now that we have the partitions ready we use it for the the first model list i.e. lasso,ridge and elastic net, the difference between them is that by the value of alpha, we also remove the first and last row as per the intructions and to remove unneccesary complexity

x <- model.matrix(Actually.Malicious~., train.data)

y <- ifelse(train.data$Actually.Malicious == "YES", 1, 0)

x.test <- model.matrix(Actually.Malicious ~., test.data)

#checking for personal inquiry

summary(test.data$Actually.Malicious)

#lasso

cv.lasso <- cv.glmnet(x, y, alpha = 1, family = "binomial")
probabilities.lasso <- cv.lasso %>% predict(newx = x.test, type = "response")
predicted.classes.lasso <- as.factor(ifelse(probabilities.lasso > 0.5, "YES", "NO"))
confusionMatrix(test.data$Actually.Malicious, predicted.classes.lasso)
summary(predicted.classes.lasso)
coef(cv.lasso)
cv.lasso$beta
#elastic net regression

cv.elastic.net.regression <- cv.glmnet(x, y, alpha = 0.3, family = "binomial")
probabilities.elastic.net.regression <- cv.elastic.net.regression %>% predict(newx = x.test, type= "response")
predicted.classes.elastic.net.regression <- as.factor(ifelse(probabilities.elastic.net.regression > 0.5, "YES", "NO"))
summary(cv.elastic.net.regression)
str(cv.elastic.net.regression)
coef(cv.elastic.net.regression)
View(predicted.classes.elastic.net.regression)
confusionMatrix(predicted.classes.elastic.net.regression, test.data$Actually.Malicious)

#ridge

cv.ridge <- cv.glmnet(x, y, alpha = 1, family = "binomial")
probabilities.ridge <- cv.ridge %>% predict(newx = x.test, type= "response")
predicted.classes.ridge <- as.factor(ifelse(probabilities.ridge > 0.5, "YES", "NO"))
summary(predicted.classes.ridge)
str(predicted.classes.ridge)
View(predicted.classes.ridge)
confusionMatrix(predicted.classes.ridge, test.data$Actually.Malicious)


#2nd methods:

#without defining trees/nodes:

#bagging
bagging = bagging(Actually.Malicious ~ ., data = train.data,coob = TRUE)
pred.bagging = bagging %>% predict(test.data)
summary(pred.bagging)
summary(test.data$Actually.Malicious)
confusionMatrix(pred.bagging, test.data$Actually.Malicious)
#coefficients$bagging

coef(bagging)

#ctree
Classification.Tree = ctree(Actually.Malicious ~ ., data = train.data)
pred.ctree = Classification.Tree %>% predict(test.data)
confusionMatrix(pred.ctree, test.data$Actually.Malicious)

#randomforest
Random.Forest = randomForest(Actually.Malicious ~ ., data = train.data, ntree=50)
pred.Random.Forest = Random.Forest %>% predict(test.data)
confusionMatrix(pred.Random.Forest, test.data$Actually.Malicious)
importance(Random.Forest)
summary(Random.Forest)

summary(train.data$Actually.Malicious)

#data conversion for Binary logistic regression
train.data$status[train.data$Actually.Malicious == "YES"] = 1 
train.data$status[train.data$Actually.Malicious == "NO"] = 0
test.data$status[test.data$Actually.Malicious == "YES"] = 1 
test.data$status[test.data$Actually.Malicious == "NO"] = 0
str(train.data)

#binarylogisticregression
str(train.data)
Binarylogisticregression = step(glm(Actually.Malicious ~ ., data = train.data, family = 'binomial', maxit = 25))

pred.Binarylogisticregression = Binarylogisticregression %>% predict(test.data)

summary(test.data$Download.Speed)

summary(train.data$Download.Speed)

predictedclasses.Binarylogisticregression = as.factor(ifelse(pred.Binarylogisticregression > 0.5, "YES", "NO"))

confusionMatrix(predictedclasses.Binarylogisticregression, test.data$Actually.Malicious)

#there's a variable in the test data that was not available in the train data hence dropping this method or if to be done resample the train data and follow all the steps from start again

# I would choose the elastic net regression because its showing the best accuracy, specificity and sensitivity





summary(Random.Forest)


#Str of given structure of model
models.list1 <- c("Logistic Ridge Regression",
                  "Logistic LASSO Regression",
                  "Logistic Elastic-Net Regression")
models.list2 <- c("Classification Tree",
                  "Bagging Tree",
                  "Random Forest")
myModels <- c("Binary Logistic Regression",
              sample(models.list1,size=1),
              sample(models.list2,size=1))
myModels %>% data.frame 

#ACTUAL recommended to be MY MODEL:
myModels <- c(Binarylogisticregression,
              bagging,
              cv.elastic.net.regression)
myModels %>% data.frame 

#HYPERPARAMETER TUNING!!!!!!!!!!!


###glmnet() is a R package which can be used to fit Regression models,lasso model and others. Alpha argument determines what type of model is fit. When alpha=0, Ridge Model is fit and if alpha=1, a lasso model is fit.

###cv.glmnet() performs cross-validation, by default 10-fold which can be adjusted using nfolds. A 10-fold CV will randomly divide your observations into 10 non-overlapping groups/folds of approx equal size. The first fold will be used for validation set and the model is fit on 9 folds. Bias Variance advantages is usually the motivation behind using such model validation methods. In the case of lasso and ridge models, CV helps choose the value of the tuning parameter lambda.


#by changing lambda to $lambda.min


#elastic net regression

cv.elastic.net.regression1 <- cv.glmnet(x, y, alpha = 0.3, family = "binomial", lambda = cv.elastic.net.regression$lambda.min)
probabilities.elastic.net.regression1 <- cv.elastic.net.regression1 %>% predict(newx = x.test, type= "response")
predicted.classes.elastic.net.regression1 <- as.factor(ifelse(probabilities.elastic.net.regression1 > 0.5, "YES", "NO"))
summary(cv.elastic.net.regression1)
str(cv.elastic.net.regression1)
coef(cv.elastic.net.regression1)
View(predicted.classes.elastic.net.regression1)
confusionMatrix(predicted.classes.elastic.net.regression1, test.data$Actually.Malicious)


#second tuning by changing lambda to max from the lambdas we have:

#elastic net regression

cv.elastic.net.regression2 <- cv.glmnet(x, y, alpha = 0.3, family = "binomial", lambda = 0.104)
probabilities.elastic.net.regression2 <- cv.elastic.net.regression2 %>% predict(newx = x.test, type= "response")
predicted.classes.elastic.net.regression2 <- as.factor(ifelse(probabilities.elastic.net.regression2 > 0.5, "YES", "NO"))
summary(cv.elastic.net.regression2)
str(cv.elastic.net.regression2)
coef(cv.elastic.net.regression2)
View(predicted.classes.elastic.net.regression2)
confusionMatrix(predicted.classes.elastic.net.regression, test.data$Actually.Malicious)


#elastic net regression

cv.elastic.net.regression3 <- cv.glmnet(x, y, alpha = 0.3, family = "binomial", lambda = ((0.1040082428+0.0010896067)/2))
probabilities.elastic.net.regression3 <- cv.elastic.net.regression3 %>% predict(newx = x.test, type= "response")
predicted.classes.elastic.net.regression3 <- as.factor(ifelse(probabilities.elastic.net.regression3 > 0.5, "YES", "NO"))
summary(cv.elastic.net.regression3)
str(cv.elastic.net.regression3)
coef(cv.elastic.net.regression3)
View(predicted.classes.elastic.net.regression3)
confusionMatrix(predicted.classes.elastic.net.regression3, test.data$Actually.Malicious)





#TREE BASED
#iterations1

bagging1 = bagging(Actually.Malicious ~ ., data = train.data[,-15],coob = TRUE, ntree=20, nbagg=25, minsplit=2)
pred.bagging1 = bagging1 %>% predict(test.data)
confusionMatrix(pred.bagging1, test.data$Actually.Malicious)
str(test.data)


#ntree:	
##Number of trees to grow. This should not be set to too small a number, to ensure that every input row gets predicted at least a few times.
#mtry:	
##Number of variables randomly sampled as candidates at each split. Note that the default values are different for classification (sqrt(p) where p is number of variables in x) and regression (p/3)
#nodesize:	
##Minimum size of terminal nodes. Setting this number larger causes smaller trees to be grown (and thus take less time). Note that the default values are different for classification (1) and regression (5).
##nbagg	
###an integer giving the number of bootstrap replications.
##coob	
###a logical indicating whether an out-of-bag estimate of the error rate (misclassification error, root mean squared error or Brier score) should be computed. See predict.classbagg for details.



#iterations2

bagging2 = bagging(Actually.Malicious ~ ., data = train.data[,-15],coob = TRUE, ntree=25, nbagg=20, minsplit=3)
pred.bagging2 = bagging2 %>% predict(test.data)
confusionMatrix(pred.bagging2, test.data$Actually.Malicious)
str(test.data)

#iterations3

bagging3 = bagging(Actually.Malicious ~ ., data = train.data[,-15],coob = TRUE, ntree=20, nbagg=25, minsplit=2)
pred.bagging3 = bagging3 %>% predict(test.data)
confusionMatrix(pred.bagging3, test.data$Actually.Malicious)
str(test.data)


#now lets make a data set of all the predictions that we have so we make confusion matrix easily:
deet = test.data[,c("Actually.Malicious","TLD")]
deet$pred.bagging = pred.bagging
deet$predicted.classes.elastic.net.regression=predicted.classes.elastic.net.regression
deet$pred.bagging1 = pred.bagging1
deet$predicted.classes.elastic.net.regression1 = predicted.classes.elastic.net.regression1
deet$pred.bagging2 = pred.bagging2
deet$predicted.classes.elastic.net.regression2 = predicted.classes.elastic.net.regression2
deet$pred.bagging3 = pred.bagging3
deet$predicted.classes.elastic.net.regression3 = predicted.classes.elastic.net.regression3
deet = deet[,-2]
test2 = subset(ML.cleaned, train_ind == 0)[,c(1,16)]
str(test2)
summary(test2$Initial.Statistical.Analysis)
deet$ini[test2$Initial.Statistical.Analysis == "Correctly Identified as Clean"] = "NO"
deet$ini[test2$Initial.Statistical.Analysis == "Correctly Identified as Malware"] = "YES"
deet$ini[test2$Initial.Statistical.Analysis == "Incorrectly Identified as Clean"] = "NO"
deet$ini[test2$Initial.Statistical.Analysis == "Incorrectly Identified as Malware"] = "YES" 
str(deet)
summary(deet)
deet$ini = as.factor(deet$ini)
confusionMatrix(deet$ini, deet$Actually.Malicious)
