#Importing necessary libraries to be used (if you dont have these libraries installed first install them by using; install.packages("libraryname"))

library(tidyverse)
library(corrplot)
library(data.table)
library(readr)
library(dplyr)
library(caret)
library(glmnet)
library(party)
library(ipred)
library(randomForest)

#Viewing the data
##We name the initial partially cleaned data set as MLini
MLini <- read.csv("C:/Users/fe/Downloads/MLDATASET_PartiallyCleaned.csv", header = T)
str(MLini) 
summary(MLini)
summary(MLini$How.Many.Times.File.Seen)
summary(MLini$Threads.Started)

#using hist function to draw histogram to check the data
hist(MLini$How.Many.Times.File.Seen)
hist(MLini$Threads.Started) 

#cleaning data as per instructions
MLini$How.Many.Times.File.Seen[MLini$How.Many.Times.File.Seen>=65535] <- NA
#we figured that the value we replaced with NA was an outlier and have decided to remove it, an alternate method could have been to replace it by the median value
# using summary and histogram function to check if we have successfully removed the outlier with NA
summary(MLini$How.Many.Times.File.Seen)
hist(MLini$How.Many.Times.File.Seen)
# now doing the same i.e. removing the outlier from the threads started column and then converting it to a categorical variable. we say that any value above 5 is equal to 5 threads started
MLini$Threads.Started[MLini$Threads.Started>=5] <-5
hist(MLini$Threads.Started)
#converting the numeric variable to categorical variable
MLini$Threads.Started = as.factor(MLini$Threads.Started)
#normalizing the characters in URL by using the log function
MLini$Characters.in.URL = log(MLini$Characters.in.URL)
#removing all the NA and blank values by na.omit() function
ML.cleaned = na.omit(MLini)
116249
#now that we have cleaned the data we will create test and train data before going on training the models; the instructions are against practice because it says to take 30% in train, usually we take 70% in train and 30% in test
set.seed(10288996)
sepo = round(nrow(ML.cleaned)*0.3)
train_ind = sample_n(ML.cleaned, sepo)[,-c(1,16)]
str(train_ind)
train.data = ML.cleaned[as.numeric(rownames(train_ind)),][,-c(1,16)]
test.data = ML.cleaned[-(as.numeric(rownames(train_ind))),][,-c(1,16)]
str(train.data)
str(test.data)
nrow(train.data)
nrow(test.data)
# now that we have the partitions ready we use it for the the first model list i.e. lasso,ridge and elastic net, the difference between them is that by the value of alpha, we also remove the first and last row as per the intructions and to remove unneccesary complexity
x <- model.matrix(Actually.Malicious~., train.data)
y <- ifelse(train.data$Actually.Malicious == "YES", 1, 0)
x.test <- model.matrix(Actually.Malicious ~., test.data)

#checking for personal inquiry
summary(test.data$Actually.Malicious)

#lasso
cv.lasso <- cv.glmnet(x, y, alpha = 1, family = "binomial")
probabilities.lasso <- cv.lasso %>% predict(newx = x.test)
predicted.classes.lasso <- as.factor(ifelse(probabilities.lasso > 0.5, "YES", "NO"))

confusionMatrix(predicted.classes.lasso, test.data$Actually.Malicious)

#elastic net regression
cv.elastic.net.regression <- cv.glmnet(x, y, alpha = 0.3, family = "binomial")
probabilities.elastic.net.regression <- cv.elastic.net.regression %>% predict(newx = x.test)
predicted.classes.elastic.net.regression <- as.factor(ifelse(probabilities.elastic.net.regression > 0.5, "YES", "NO"))
summary(cv.elastic.net.regression)
str(cv.elastic.net.regression)
coef(cv.elastic.net.regression)
View(predicted.classes.elastic.net.regression)
confusionMatrix(predicted.classes.elastic.net.regression, test.data$Actually.Malicious)

#ridge
cv.ridge <- cv.glmnet(x, y, alpha = 1, family = "binomial")
probabilities.ridge <- cv.ridge %>% predict(newx = x.test)
predicted.classes.ridge <- as.factor(ifelse(probabilities.ridge > 0.5, "YES", "NO"))
summary(predicted.classes.ridge)
str(predicted.classes.ridge)
View(predicted.classes.ridge)
confusionMatrix(predicted.classes.ridge, test.data$Actually.Malicious)

#2nd methods:
#without defining trees/nodes:

bagging = bagging(Actually.Malicious ~ ., data = train.data,coob = TRUE)
pred.bagging = bagging %>% predict(test.data)
confusionMatrix(pred.bagging, test.data$Actually.Malicious)

Classification.Tree = ctree(Actually.Malicious ~ ., data = train.data)
pred.ctree = Classification.Tree %>% predict(test.data)
confusionMatrix(pred.ctree, test.data$Actually.Malicious)

Random.Forest = randomForest(Actually.Malicious ~ ., data = train.data, ntree=50)
pred.Random.Forest = Random.Forest %>% predict(test.data)
confusionMatrix(pred.Random.Forest, test.data$Actually.Malicious)
importance(Random.Forest)
summary(Random.Forest)

summary(train.data$Actually.Malicious)
sl$churned[sl$CATEGORY == "At Risk" ] <- 1

train.data$status[train.data$Actually.Malicious == "YES"] = 1 
train.data$status[train.data$Actually.Malicious == "NO"] = 0
test.data$status[test.data$Actually.Malicious == "YES"] = 1 
test.data$status[test.data$Actually.Malicious == "NO"] = 0
str(train.data)
Binarylogisticregression = glm(status ~ ., data = train.data, family = 'binomial', maxit = 25)[,-14]
 pred.Binarylogisticregression = Binarylogisticregression %>% predict(test.data)
summary(test.data$Download.Speed)
summary(train.data$Download.Speed)
predictedclasses.Binarylogisticregression = as.factor(ifelse(pred.Binarylogisticregression > 0.5, "YES", "NO"))
confusionMatrix(predictedclasses.Binarylogisticregression, test.data$Actually.Malicious)
#there's a variable in the test data that was not available in the train data hence dropping this method or if to be done resample the train data and follow all the steps from start again
# I would choose the elastic net regression because its showing the best accuracy, specificity and sensitivity




#iterations
bagging1 = bagging(Actually.Malicious ~ ., data = train.data[,-15],coob = TRUE, ntree=20)
pred.bagging1 = bagging1 %>% predict(test.data)
confusionMatrix(pred.bagging1, test.data$Actually.Malicious)
str(test.data)

Classification.Tree1 = ctree(Actually.Malicious ~ ., data = train.data)
pred.ctree1 = Classification.Tree1 %>% predict(test.data)
confusionMatrix(pred.ctree1, test.data$Actually.Malicious)

Random.Forest1 = randomForest(Actually.Malicious ~ ., data = train.data[,-15], ntree=14)
pred.Random.Forest1 = Random.Forest1 %>% predict(test.data)
confusionMatrix(pred.Random.Forest1, test.data$Actually.Malicious)
importance(Random.Forest)
summary(Random.Forest)

#You can also take your sample like this:
#train_ind = rbinom(nrow(ML.cleaned), 1, 0.3)
#train.data = subset(ML.cleaned, train_ind == 1)
#test.data = subset(ML.cleaned, train_ind == 0)

#switch the locations to; confusionMatrix(test.data$Actually.Malicious, pred.Random.Forest1)